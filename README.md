# Υπολογιστικό σύστημα
Η εργασία έτρεξε σε επεξεργαστή με αρχιτεκτονική x86_64.

# Μοντέλο Επεξεργαστή
Intel(R) Core(TM) i5-6500 CPU @ 3.20GHz

# Αριθμός πυρήνων επεξεργαστή
4

# Έκδοση Λειτουργικού Συστήματος
Ubuntu 18.04.6 LTS

# Έκδοση Μεταγλωττιστή
gcc version : 7.5.0

# Άσκηση 1

# Αποτελέσματα και δεδομένα εισόδου 
-> Όλες οι δοκιμές με διαφορετικά ορίσματα γίνανε 5 φορές η κάθε μια για να βρέθει ο μέσος όρος των αποτελεσμάτων.

Το πρόγραμμα έχει ως ορίσματα <number_of_threads> <throw_count> όπου throw_count ο αριθμός των ρίψεων.


# Το πρόγραμμα pi_comp.c έτρεξε αρχικά με ορίσματα 2 | 100000

() Serial time : 0,0054 |||| Parallel time : 0,0028 |||| Single thread time : 0,0027
() Pthreads time : 0.0035 


# Όμοια για ορίσματα 2 | 1000000

() Serial time : 0,0522 |||| Parallel time : 0,0273 |||| Single thread time : 0,0271
() Pthreads time : 0.0281


# Για ορίσματα 2 | 10000000

() Serial time : 0.5199 |||| Parallel time : 0.2708 |||| Single thread time : 0.2704
() Pthreads time : 0.2801


# Για ορίσματα 4 | 100000

() Serial time : 0,0052 |||| Parallel time : 0,0251 |||| Single thread time : 0,0014
() Pthreads time : 0.0029


# Για ορίσματα 4 | 1000000

() Serial time : 0,052 |||| Parallel time : 0,0444 |||| Single thread time : 0,02
() Pthreads time : 0.0269


# Για ορίσματα 4 | 10000000

() Serial time : 0.5211 |||| Parallel time : 0.2348 |||| Single thread time : 0.1829
() Pthreads time : 0.2626


# Σύγκριση OpenMP με σειριακό αλγόριθμο
Παρατηρείται μεγάλη επιτάχυνση σε σχέση με τον σειριακό αλγόριθμο καθώς οι υπολογισμοί τρέχουν παράλληλα.

# Σύγκριση OpenMP με Pthreads
Παρατηρείται παρόμοια επίδοση μεταξύ των δύο βιβλιοθηκών για τα περισσότερα ορίσματα. Ωστόσο, για ορίσματα 4 | 10000000 η OpenMp ειναι αποδοτικότερη της Pthreads. Αυτό γίνεται γιατί η Pthreads είναι thread-based ενώ η OpenMP είναι task-based, δηλαδή η OpenMP για κάθε νήμα παραχωρεί και έναν πυρήνα επεξεργαστή. Ως αποτέλεσμα, υπάρχει μεγαλύτερη δυνατότητα κλιμάκωσης στην OpenMP καθώς μέχρι εναν αριθμό νημάτων έχουμε λιγότερο overhead σε σχέση με την Pthreads.

# Άσκηση 2

## Δεδομένα εισόδου
Όλα το πείραμα εκτελέστηκε με τα ορίσματα για τις διαστάσεις να είναι 10000 10000.

# Γενικά
Για να φτιάξουμε το εκτελέσιμο τρέχουμε make mat και για να τρέξουμε το πείραμα python3 matrix_script.py.
Μέσω του script εκτελούμε πολλές φορές το πρόγραμμα με ίδια ορίσματα για να έχουμε πιο
έμπιστα αποτελέσματα. Στη συνέχεια αναθέτουμε διαφορετικό αριθμό νημάτων και επιλέγουμε
διαφορετικό schedule.
Στο πρόγραμμα που δινόταν τροποποιήθηκαν οι συναρτήσεις Gen_matrix και Omp_mat_vect.
Στην Gen_matrix αυτό που αλλάξαμε είναι ότι κάτω από την διαγώνιο όλα τα στοιχεία
είναι ίσα με 0.
Στην Omp_mat_vect προσθέσαμε το clause schedule(runtime) έτσι ώστε να μπορούμε να
αλλάξουμε την ανάθεση των επαναλήψεων στα νήματα χωρίς να πείραζουμε τον πηγαίο
κώδικα. Επίσης τροποποιήσαμε το εσωτερικό loop έτσι ώστε να λαμβάνει υπόψη τα μηδενικά
στοιχεία και να μην τα συμπεριλαμβάνει στον υπολογισμό. Τέλος, εισάγουμε την μεταβλητή
temp και χρησιμοποιούμε μόνο αυτή για τον υπολογισμό του εκάστοτε στοιχείου του διανύσματος.
Με αυτόν τον τρόπο αποφεύγουμε το false sharing εφόσον στο διάνυσμα y γράφει κάθε νήμα μία
φορά για κάθε υπολογισμό στοιχείου που κάνει.
Στο πείραμά μας δοκιμάζουμε για schedules τα static, dynamic, guided, auto με default chunk
size = 1. Σε περίπτωση που θέλει ο χρήστης να αλλάξει είτε τα ορίσματα είτε τις τιμές για
το schedule, μπορεί πολύ εύκολα να το κάνει μέσω του matrix_script.

## Αποτελέσματα

>> Serial time: 0.13695

### THREADS = 2 ###
*******************
> Schedule = static
Average execution time: 0.10325
-------------------------------
> Schedule = dynamic
Average execution time: 0.07064
-------------------------------
> Schedule = guided
Average execution time: 0.10367
-------------------------------
> Schedule = auto
Average execution time: 0.10335
-------------------------------

### THREADS = 4 ###
*******************
> Schedule = static
Average execution time: 0.06292
-------------------------------
> Schedule = dynamic
Average execution time: 0.03724
-------------------------------
> Schedule = guided
Average execution time: 0.06281
-------------------------------
> Schedule = auto
Average execution time: 0.06283
-------------------------------

## Παρατηρήσεις
Εκ πρώτης όψεως η βελτίωση είναι προφανής, με όποιο schedule κι αν επιλέξουμε. Παρόλ'αυτά,
δεν είναι η αναμενόμενη. Με εξαίρεση το schedule=dynamic, για threads=2 έχουμε speedup
ίσο με 1.33 ενώ για threads=4 αγγίζει το 2.17, νούμερα που απέχουν πολύ από την επιθυμητή
γραμμική επιτάχυνση.
Όταν όμως επιλέγουμε schedule=dynamic τα πράγματα είναι διαφορετικά. Για threads=2 έχουμε
speedup ίσο με 1.95 και για threads=4 πλησιάζει το 3.7, πολύ πιο κοντά στην γραμμική
επιτάχυνση.
Αν το σκεφτεί κανείς, τα νούμερα αυτά είναι λογικά. Αυτό που κάνει το dynamic schedule
είναι να αναθέτει δυναμικά στα νήματα iterations από το for loop. Σε κάποιο πρόβλημα στο
οποίο κάθε iteration εκτελεί περίπου τον ίδιο φόρτο εργασίας, δεν θα χρειαζόταν κάτι τέτοιο.
Στο δικό μας πρόβλημα όμως, λόγω της ιδιότητας του άνω τριγωνικού πίνακα, όσο "προχωράμε" στους
υπολογισμούς του διανύσματος y, τόσο λιγότερες πράξεις χρειάζονται. Άρα ο φόρτος εργασίας πρέπει
κάπως να μοιραστεί ομοιόμορφα στα νήματα. Με το dynamic schedule κάθε φορά που ένα νήμα τελειώνει
την εργασία του, ζητάει από το runtime system να του ανατεθεί η επόμενη. Δηλαδή όταν ένα νήμα
εκτελεί μια πιο "βαριά" εργασία και ένα άλλο μια πιο "ελαφριά", το δεύτερο θα αναλάβει όσες
περισσότερες μπορεί στον ίδιο χρόνο που θα κάνει να ολοκληρώσει η πρώτη. Έτσι αυξάνουμε την απόδοση
του προγράμματος, πόσο εκμεταλλευόμαστε δηλαδή τον κάθε πυρήνα.

## False Sharing
Δοκιμάσαμε το εξής πείραμα. Τρέξαμε το πρόγραμμα ακολουθώντας την μεθοδολογία του αρχικού προγράμματος
που μας είχε δωθεί και με μία ελαφρώς αλλαγμένη, η οποία βρίσκεται αυτή την στιγμή στον πηγαίο κώδικα.
Τα αποτελέσματα βρίσκονται στον κατάλογο FalseSharing και είναι αρκετά ενδιαφέροντα.
Καταρχάς, η αλλαγή που κάναμε ήταν να υπολογίζουμε κάθε φορά το αποτέλεσμα στην μεταβλητή temp και να
το γράφουμε μία φορά στο y. Σε αντίθεση με τον άλλο default τρόπο στον όποιο υπολογίζαμε το αποτέλεσμα
μέσα στο ίδιο το y, γράφοντας έτσι σε αυτό πολλαπλές φορές.
Τα αποτελέσματα χωρίς να έχουμε έντονο false sharing τα είδαμε παραπάνω και σε γενικές γραμμές ήταν
αναμενόμενα. 
Με τον deafult τρόπο περιμένει κανείς ότι θα έχουμε απλά χειρότερους αναλογικούς όμως χρόνους με τα
προηγούμενα αποτελέσματα, κι έτσι κι έγινε...με μια εξαίρεση όμως, το dynamic schedule. Εδώ η χειροτέρευση
του χρόνου ήταν πολύ χειρότερη, σε σημείο που μάλιστα το πρόγραμμα εκτελείτε πιο αργά και από την
σειριακή προσέγγιση. Γιατί γίνεται όμως αυτό;
### Πιθανή εξήγηση
Έχοντας dynamic schedule όλα τα νήματα τερματίζουν περίπου στον ίδιο χρόνο. Αυτό σημαίνει ότι καθόλη την
διάρκεια ζωής τους προσπελαύνουν το y όλα μαζί, δημιουργώντας έτσι πολύ πιο έντονο το φαινόμενο του false
sharing. Όταν όμως δεν έχει γίνει η σωστή κατανομή του φόρτου εργασίας, τότε κάποια νήματα θα τερματίσουν
πολύ πιο νωρίς από κάποια άλλα και γενικότερα ο αριθμός των "ζωντανών" νημάτων θα μειώνεται, έχοντας ως
αποτέλεσμα να μην έχουμε τόσες ταυτόχρονες εγγραφές στο y.
